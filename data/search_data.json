{
	"data": [
		{
			"title": "AI classifier",
			"text": "in some cases it may not be feasible to differentiate between the background and the signal based solely on intensity values this makes the use of threshold as a segmentation technique impractical in such situations to overcome this limitation imagec allows the use of artificial intelligence models for object segmentation and classification as an alternative to threshold techniques the image plane is forwarded to a pre-trained ai model the output is an prediction whereby each prediction is assigned to a output class and a confidence using the imagec ai classifier the predicted output is transformed to classified objects deep learning models on startup imagec searches the models folder for compatible ai models and presents them in the drop-down menu for selection in the actual implementation of imagec yolov5 and u-net model architecture are supported imagec expects a rdf yaml file beside the weight file pt onnx this resource definition file according to the bio image zoo schema rdf definition describes the model input and output parameters required by imagec for correct interpretation of the prediction output after downloading a new model either from imagec ai models or bioimage model zoo unzip the content and copy the unpacked folder to the models directory icon_open of the imagec installation directory press the refresh button icon_refresh and select the model from the model path dropdown most of the settings are taken automatically based on the parsed information of the rdf yaml file for non onnx models the number of model classes must be set manually bestpractice select the number of output classes and select an imagec object class to associate with each output class imagec is compatible with a wide range of models of bioimage model zoo imagec compatible models for object segmentation can be downloaded from imagec org below the download section copy the downloaded model to the file models folder imagec will load all models from this folder automatically on startup and provides them in the ai model dropdown for selection deep learning engines imagec actually includes the engines pytorch and onnxruntime using pytorch torchscript models are supported with onnxruntime all models saved on onnx format can be used tip imagec supports pytorch torchscript format and onnxruntime s onnx format the provided ai classifier combines object segmentation and classification in one command since both is done by the trained ai model in one step when an image is forwarded to the ai model the result is a prediction of objects with each predicted object having a confidence and being assigned to an ai output class imagec ai classifier providers a filter tab for each possible output class of the ai model these filters can be used to assign the predicted output classes of the ai model to an imagec object class thresholds thresholds in the context of ai are probability thresholds which define the minimum probability of a detection output to mark the prediction as valid mask threshold a typical output of an ai model for image segmentation is a matrix containing a probability value for each pixel where each of these probability values represents the probability that the pixel belongs to the background or to the foreground the mask threshold defines the minimum probability required for a pixel to be defined as a foreground pixel class threshold the class threshold is a probability value ranging from zero to one where one represents 100 once the image has been processed by the ai network a matrix of probabilities is created one of these probabilities is the probability that a detected object can be assigned to one of the defined classes with the class threshold it is possible to define the minimum probability that a detected object must have in order to be identified as an object of a class",
			"category": "Classification",
			"url": "/docs/stable/commands/classification/classifier_ai",
			"blurb": "In some cases, it may not be feasible to differentiate between the background and the signal based solely on...",
			"type": "documentation"
		},
		{
			"title": "Benchmark",
			"text": "imagec is designed for high-throughput image processing the following benchmarks provide an indication of the expected analysis speed",
			"category": "Dev",
			"url": "/docs/stable/dev/benchmark",
			"blurb": "ImageC is designed for high-throughput image processing. The following benchmarks provide an indication of the...",
			"type": "documentation"
		},
		{
			"title": "Blur",
			"text": "blur algorithms are used to reduce image noise and details imagec provides two different blur algorithms normal blur and gaussian blur for both the filter kernel size can be set the larger the kernel the more details are removed from the image gaussian blur uses a gaussian function to blur the image compared to the normal blur gaussian blur tends to preserve edges slightly better and avoids sharp transitions between blurred regions tip bigger filter kernels removes more noise and details from the image use gaussian blur to preserve edges in a better way than normal blur in image processing a kernel convolution matrix or mask is a small matrix used for blurring sharpening embossing edge detection and more this is accomplished by doing a convolution between the kernel and an image or more simply when each pixel in the output image is a function of the nearby pixels including itself in the input image the kernel is that function",
			"category": "Image Processing",
			"url": "/docs/stable/commands/image_processing/blur",
			"blurb": "Blur algorithms are used to reduce image noise and details. ImageC provides two different blur algorithms, normal...",
			"type": "documentation"
		},
		{
			"title": "Building",
			"text": "imagec is written in the c programming language and uses the linux operating system during the build process it is compiled for linux windows and macos for developing vscode and a docker devcontainer is used the devcontainer is actually only tested for linux operating system warning if you want to try developing under windows you can try docker for windows together with the windows subsystem for linux wsl however we do not provide any support or guarantee that it works preparation download vscode clone imagec repo https github com joda01 imagec git open the cloned directory using vscode install dev containers extension and reopen open the project in container first time to build imagec uses conan build system the artifacts needed for building are stored in our imagec artifactory first time you want to build please contact us and request access to the artifactory request artifactory request support imagec org execute build_linux sh --init and enter your received token to login at the artifactory execute build_linux sh --make execute build_linux sh --build the build artifacts are placed into build build output",
			"category": "Dev",
			"url": "/docs/stable/dev/building",
			"blurb": "ImageC is written in the C++ programming language and uses the Linux operating system. During the build process, it...",
			"type": "documentation"
		},
		{
			"title": "Cell Segmentation",
			"text": "this pre-trained ai model can be used for brightfield cell segmentation after download unzip and copy the whole folder into imagec_installation_directory models language-sql highlight download site baseurl downloads university_of_sbg_brightfield_cell_segmentation_v3 zip",
			"category": " Posts",
			"url": "/2025/05/31/ai-model-cells",
			"blurb": "This pre-trained AI model can be used for brightfield cell segmentation. After download unzip and copy the whole...",
			"type": "blog"
		},
		{
			"title": "Classification",
			"text": "the concept behind imagec is to run pipelines containing image pre-processing and object segmentation steps with the goal of extracting regions of interest from the input images for each extracted object the origin information image image channel z-stack and t-stack and some metrics are stored in advanced each object is classified for object statistics calculation and later quantification for classification imagec provides the annotations object class every object is annotated with exact one object class classes the first step before creating pipelines or starting the analysis is to define which classes are needed for object classification in your application using the classification tab link docs stable first_steps operation md classification-tab classes represents the populations which should be distinguished use the plus button to add a new class in addition to the color the name and the default displayed metrics for the class can be specified using the symbol allows to group classes for a better reading in the selection tab instead of manually specifying all required classes imagec provides the ability to populate the classification settings from the image channel information using the magic stick button bestpractice it is a best practice to use the fluorophor as prefix followed by the object type dapi nucleus cy5 spots cy spots-in-cell for processed objects use the process operator coloc cy5cy7-spots classification presets imagec also allows to create classification presets by selecting a preset from the drop down of the plus button a classification preset is a set of predefined classes which can be loaded and shared with others the idea behind a preset is making results easier comparable by using the same nomenclator for each analysis using the save as template option allows to create a new preset from an existing settings",
			"category": "Fundamentals",
			"url": "/docs/stable/fundamentals/classification",
			"blurb": "The concept behind ImageC is to run pipelines containing image pre-processing and object segmentation steps with the...",
			"type": "documentation"
		},
		{
			"title": "Classifier",
			"text": "the classifier command is used to convert regions of interest formally extracted from the image using a segmentation algorithm such as threshold link docs stable commands binary_image_processing threshold md into objects where each object is assigned to an object class for classified link docs stable fundamentals classification md objects metrics are calculated they are stored to the resulting database and can be used in further object-processing steps imagec s classifier provides several filter methods which can be used to to filter out artefact all objects which match the filter criteria are assigned to the match class objects not matching the filter criteria are assigned to the no match the filter can be set for each threshold classes link docs stable commands binary_image_processing threshold md threshold-classes individually this allows the classifier to assign each roi of a threshold classes link docs stable commands binary_image_processing threshold md threshold-classes to a specific match and no match object class use the icon_add button to add as many filters as needed as a rule one filter for each threshold class is used tip see section objects link docs stable fundamentals objects md for more detailed information about object metrics objects are extracted from a binary image representing thee regions of interest of the image for each extracted object a class is assigned and metrics are measured objects are stored to the resulting database and can be used in further pipeline steps",
			"category": "Classification",
			"url": "/docs/stable/commands/classification/classifier",
			"blurb": "The Classifier command is used to convert regions of interest, formally extracted from the image using a segmentation...",
			"type": "documentation"
		},
		{
			"title": "Colocalization",
			"text": "the colocalization command is used to determine objects which intersect with each other up to four object classes can be given as input for those the colocalization is calculated a spot is defined as colocalizing if for each given input class a overlapping object is found the imagec colocalization command allows to reclassify those objects which colocalizes for a further processing of the objects object tracking is the process of linking two objects either from different time frames or channels using the same tracking id for all objects this makes it possible to display objects from different sources that physically represent one object colocalizing handling once an object colocalizes one of the move or copy operations will be applied to that objects the move operator applies a new object class to the object object id keeps the same as before the copy operator creates a new object and assigns the new object class only to the new object a new object id is generated and the origin object id of the newly created object is set to the object id of the origin object the origin object keeps untouched in addition a new object is generated which the overlapping area colocalization area of the overlapping objects all colocating objects including the newly created coloc area object are given a common tracking id in the results objects with the same tracking id are placed next to each other allowing matching objects to be compared if from each input class an object overlaps with an other object from the other input classes the object is defined as colocalizing the overlapping area is called the coloc area and a new object for further processing of this area is generated in addition ech colocalizing object gets the same tracking id assigned",
			"category": "Measurement",
			"url": "/docs/stable/commands/measurement/colocalization",
			"blurb": "The colocalization command is used to determine objects which intersect with each other. Up to four object classes...",
			"type": "documentation"
		},
		{
			"title": "Color filter",
			"text": "if the input image is an rgb 8-bit color image the color image must first be converted to a grey scale image this conversion is done by the color filter command with this filter it is possible to define the color range containing the region of interests for each region of interest in a different color to extract a separate pipeline with a separate color filter must be created the resulting image is a gray scale image showing only the image regions filtered by the selected color range in a next step further image processing steps can be applied for color images three values are stored per pixel which contain the color information the rgb-format is one widely used format used to store these color information rgb stores information about the red green and blue parts of an image and is based on how the human eye perceives color the superimposition of these color components leads to our perception of color in the rgb color space it is easy to create a color tone that is correct for human perception but working with color ranges is difficult a better suited format for working with color ranges is the hsv format instead of storing the color information using red green blue in hsv format a color is defined by its color tone hue its saturation and its brightness value using hsv allows more easy to filter e g all blue tones from an image imagec is using hsv color format for that reason when working with colored images wikipedia https de wikipedia org wiki hsv-farbraum media datei hsv_cone png",
			"category": "Image Processing",
			"url": "/docs/stable/commands/image_processing/color_filter",
			"blurb": "If the input image is an RGB 8-bit color image, the color image must first be converted to a grey scale image. This...",
			"type": "documentation"
		},
		{
			"title": "Debugging",
			"text": "imagec is written in c and compiled into a binary that is executed directly on your cpu while such programmes offer the highest possible performance they have the disadvantage that in the event of a programme error the programme simply crashes and closes even though we test imagec it is still possible that we have overlooked an error causing the programme to crash in certain situations to help us identify the cause of the crash imagec can be started in debug mode once started in debug mode imagec generates a crash report that can be made available to us once the program crashes please send the debug txt to support imagec org linux open a terminal window change directory to the installation folder of imagec cd imagec_install_directory language-sql highlight start imagec with following command imagec debug txt window open windows powershell as administrator change directory to the installation folder of imagec cd imagec_install_directory language-sql highlight start imagec with following command start-process -redirectstandardoutput debug txt imagec exe macos open a terminal window change directory to the installation folder of imagec cd imagec_install_directory language-sql highlight start imagec with following command imagec debug txt",
			"category": "Dev",
			"url": "/docs/stable/dev/debugging",
			"blurb": "ImageC is written in C++ and compiled into a binary that is executed directly on your CPU. While such programmes...",
			"type": "documentation"
		},
		{
			"title": "EVAnalyzer",
			"text": "imagec is the direct successor of evanalyzer an imagej fiji plugin designed for some standard use cases in image processing especially for the ev field these pipelines are also available in imagec evanalyzer2 as described in this section evanalyzer citation sch\u00fcrz m danmayr j jaritsch m klinglmayr e benirschke h m matea c - t zimmerebner p rauter j wolf m gomes f g kratochvil z heger z miller a heuser t stanojlovic v kiefer j plank t johnson l himly m meisner-kober n 2022 evanalyzer high content imaging for rigorous characterisation of single extracellular vesicles using standard laboratory equipment and a new open-source imagej fiji plugin journal of extracellular vesicles 11 e12282 https doi org 10 1002 jev2 12282",
			"category": "Evanalyzer",
			"url": "/docs/stable/tutorials/evanalyzer/index",
			"blurb": "ImageC is the direct successor of EVAnalyzer an ImageJ/Fiji plugin designed for some standard use cases in image...",
			"type": "documentation"
		},
		{
			"title": "Edge detection",
			"text": "edge detection is a function used to highlight the edges within an image an edge is defined as a change in grey level larger rates of change in the values lead to a larger output value in the algorithm imagec provides sobel and canny edge detection the main advantages of the sobel operator are that it is simple and time efficient but produces rough edges on the other hand the canny technique produces smoother edges due to the implementation of non-maxima suppression and thresholding the disadvantage of the canny algorithm is that it is more complex and less time efficient than sobel edge detection is the process of finding edges in an image and converting them to a gradient representation sharper changes in the intensity values lead to a higher gradient",
			"category": "Image Processing",
			"url": "/docs/stable/commands/image_processing/edge_detection",
			"blurb": "Edge detection is a function used to highlight the edges within an image. An edge is defined as a change in grey...",
			"type": "documentation"
		},
		{
			"title": "Enhance contrast",
			"text": "underconstruction coming soon",
			"category": "Image Processing",
			"url": "/docs/stable/commands/image_processing/enhance_contrast",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Files Created by ImageC",
			"text": "imagec creates several files and directories on your disk some global files are created and retained even after an update to imagec while some local files are generated directly within the imagec installation folder additionally some analysis artifacts are generated when an analysis is started file types following file types can be generated by imagec endian description ------- ------------------- icdb sql database file containing results data under the hood a duckdb storage format ictbl imagec results table settings file used to reload table settings in the results view icproj imagec project file containing all project settings ictemplproj imagec project template file for reusing and sharing project settings ictempl imagec pipeline template file for reusing and sharing pipeline settings ictemplcc imagec classification template file for reusing and sharing class settings global files and directories imagec creates the following global files in the user s home directory on startup for unix based systems linux macos a folder imagec is generated for windows based systems a folder c users imagec is generated the folder contains following files and directories name description ------- ------------------- imagec user_settings json stores some global user settings like the list of last opened files imagec templates project pipeline and classification templates which the user has been created copy the new templates into this folder for easy access within imagec local files and directories imagec creates the following files and directories in the installation folder of imagec name description ------- ------------------- models copy ai models within this folder to use them within imagec hs_err_pid log error trace log of the bioformats java integration files created during analysis when an analysis is started imagec automatically creates some job artefacts in the selected image working directory if no job name was given in the project settings a unique job name is generated for each run name description ------- ------------------- working_directory imagec job_name results icdb language-sql highlight database file containing all results of the run the file can be opened with the imagec results viewer link docs stable first_steps results md or with sql knowledge using one of the duckdb clients working_directory imagec job_name profiling json language-sql highlight statistics about the execution time of each individual pipeline step working_directory imagec job_name settings icproj language-sql highlight a copy of the project settings when the job has been started working_directory imagec job_name images language-sql highlight a folder containing all control images generated during the run",
			"category": "Technical",
			"url": "/docs/stable/technical/files_created_by_imagec",
			"blurb": "ImageC creates several files and directories on your disk. Some global files are created and retained even after an...",
			"type": "documentation"
		},
		{
			"title": "Fill holes",
			"text": "underconstruction coming soon",
			"category": "Binary Image Processing",
			"url": "/docs/stable/commands/binary_image_processing/fill_holes",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Hough transformation",
			"text": "underconstruction coming soon",
			"category": "Classification",
			"url": "/docs/stable/commands/classification/hough_transformation",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Image Cache",
			"text": "the store image to cache command stores an actual image at any time to the cache image cache allows using a preprocessed image as base for further preprocessing steps in an other pipeline or in the same pipeline in a future step possible applications might be to preprocess a background for subtraction and use this preprocessed background together with the image math subtract command in other pipelines to remove it storage scope the storage scope defines either if the cached image is only available in the pipeline the command is used iteration or if the stored image can also be used across different pipelines pipeline the memory slots m0 to m10 can be used twice once for iteration and once for pipeline cache note once an image is stored to the cache it is not edited any more loading from the cache creates a new local copy of the image and the pipeline is working on this local copy but not on the cached image imagec cache is reserved place in the ram of the computer storing an image to the cache stores the actual image to this place in ram other commands can load these images from the ram in an efficient way and apply further processing steps on it",
			"category": "Image Processing",
			"url": "/docs/stable/commands/image_processing/image_cache",
			"blurb": "The store image to cache command stores an actual image at any time to the cache. Image cache allows using a...",
			"type": "documentation"
		},
		{
			"title": "Image format",
			"text": "imagec can be used with a wide range of image formats thanks to the open source library bio-formats https docs openmicroscopy org bio-formats which is shipped together with ths application following 8-bit or 16-bit grayscale and 8-bit rgb color images are supported tif tiff btif btiff btf jpg jpeg vsi ics czi nd2 lif lei fli scn sxm lim oir top stk nd bip fli msr dm3 dm4 img cr2 ch5 dib ims pic raw 1sc std spc avi cif sif aim svs arf sld a full list of all supported image formats can be found on the bio-formats homepage warning there are some special photoshop tiff formats which are not supported when using tiff images take care about using either raw tiff or the ome-tiff format for multi channel support bestpractice use raw images directly from your microscope without any pre-processing or compression for the best detection results imagec can handle multi channel images as well as big histological images without the need of any preprocessing use the images directly as they were captured by the microscope camera without any compression or pre-processing to get the best results especially for multi-channel images avoid merging the channels into an rgb color image for processing as most of the image information will be lost use the original multichannel image and use imagec pipelines to process each of the channels individually to extract the objects of interest image planes image-planes microscope images usually consist of several individual images that are summarized in a common image file this individual images are named image planes each plane is identified by its channel z-stack and time stack imagec is able to access each image plane of an image and process these planes individually based on the taken project and pipeline settings an image may comprise one or more c channels with each channel in turn consisting of a series of t time stacks and these in turn consisting of a series of z stacks the combination channel z stack z and time stack t is called image plane imagec is able to process each image plane of an image based on the taken project and pipeline settings within a pipeline select the image channel to be loaded as the starting point for this pipeline the channel is a number from 0 to x a separate pipeline must be created for each image channel required for processing in a second step it is necessary to define how z-stacks and time stacks should be processed these settings can be taken in the project tab of imagec it is possible either to process each z-stack image individually using a projection algorithm to combine all the images of a z-stack into a single stack image or to analyze exactly one image of the z-stack if a projection algorithm is to be used the algorithm to be used must be defined within the individual pipeline for the time stack it is possible either to analyze one image of a time stack or to analyze the whole time series ome xml formats-ome imagec supports reading ome xml meta data stored beside image files ome specifies a structure how image meta can be shared in a standardized way imagec tries to parse this xml data if it is found in an image and displays the meta data in a sidebar on the start screen the ome metadata contains not only image metadata for the end user but also information about the number of channels and the channel order therefore ome metadata is mandatory if multi-channel images are to be processed imagec assumes that only one channel is available if no ome metadata is found tip for a full specification ome see https ome-model readthedocs io en stable ome-xml index html big images big-images because computing resources are limited image size can be a limiting factor when working with histological images particularly during analysis one of the hardest limits is an image resolution of 46340x46340 pixels which exceeds the 32-bit signed data type limits of many common image processing algorithms in addition to this data type limitation most personal computers have limited ram which restricts the maximum image size that can be analyzed imagec solves both issues by automatically breaking large images down into smaller pieces called image tiles the maximum tile size can be specified in the project settings tab if an images is loaded which is bigger than this specified tile size imagec analyzes tile by tile instead of the whole image at once after the analyses are finished imagec will automatically combine the results from each tile to create a full image result again from a user s perspective the large image can be analyzed with imagec as is to get results for the entire image the big tiff file format breaks the the 4 gigabyte 32-bit size limit in comparison to the normal tiff format bigtiff images are usually split into tiles whereby a typical tile size is 512x512 px when analyzing imagec opens in this example 64 tiles at once and analyses one such composite tile after another this is necessary because when working with such large images the entire image cannot be loaded into ram at once warning imagec can only generate a navigation map if the large image is stored as a pyramid image when working with large images ensure that only supported image formats are used and that the image container contains a pyramid representation of the image for large images imagec generates a preview of only one tile to avoid exceeding the computer s ram limits the image map navigator within the preview window allows you to navigate through the different image areas following image formats support big images including pyramid images afi svs ims vsi ndpi ndpis jp2 tiff tif tf2 tf8 btf tif sld jpg czi",
			"category": "Fundamentals",
			"url": "/docs/stable/fundamentals/image_formats",
			"blurb": "ImageC can be used with a wide range of image formats, thanks to the open source library Bio-formats :...",
			"type": "documentation"
		},
		{
			"title": "Image math",
			"text": "the image math command can be used to combine two images using one of the provided mathematical operations input image one is the image from the last pipeline step the second image is the image configured in the input image channel settings for the second image either an image channel can be used or an image stored in the cache from a previous pipeline if from cache is not none the channel settings are ignored and the image from the selected cache slot is loaded the operating order setting allows to define if the first operand of the selected function is the image from the last pipeline step or the selected input image an image is represented as a matrix of pixel intensity values when calculating with images a matrix operation is performed which uses the pixel value at n m from both matrixes and applying the operator on that the resulting matrix after applying the operator on all elements of the matrix is the resulting image",
			"category": "Image Processing",
			"url": "/docs/stable/commands/image_processing/image_math",
			"blurb": "The image math command can be used to combine two images using one of the provided mathematical operations. Input...",
			"type": "documentation"
		},
		{
			"title": "Intensity",
			"text": "the intensity command allows to change the image brightness contrast and gamma the contrast value is a factor between one and three one means no change in contrast three means a contrast increase by a factor of three for brightness a range of -32768 and 32768 can be specified by adding this value to each pixel value in the image the brightness is increased by the specified value warning gamma correction is not yet supported by imagec in addition to setting manual image correction factors an automatic correction mode can be selected automatic contrast and brightness correction is done by calculating a histogram equalizing histogram equalizing is done in three steps step 1 calculate the histogram 65536 bins for 16-bit range step 2 calculate the cumulative distribution function cdf cdf i cdf i - 1 hist i step 3 normalize the cdf to the range 0 65535 equalization_ map i frac 65535 0 cdot cdf i total_ pixels step 4 map the pixel values from the equalization map",
			"category": "Image Processing",
			"url": "/docs/stable/commands/image_processing/intensity",
			"blurb": "The intensity command allows to change the image brightness, contrast and gamma. The contrast value is a factor...",
			"type": "documentation"
		},
		{
			"title": "Measure distance",
			"text": "the distance measure command can be used to measure the distance between all objects of two different object classes five different distances are calculated for each object combination center to center center to surface min center to surface max surface to surface min surface to surface the euclid-distance is used for distance calculation imagec calculates the distance between all objects within the two given classes in reality however often only a fraction of the calculated distants are required typically for example the distance between the spot and the cell wall would be calculated but only the distance between those spots and the cell wall where the spots are also located within the respective cell are of interest for that reason imagec allows to specify a condition for the distance calculation following conditions are supported condition description ------------ -------------- all the distance between all spots of the given classes is calculated only children only those spots that intersect with each other have their distances calculated",
			"category": "Measurement",
			"url": "/docs/stable/commands/measurement/measure_distance",
			"blurb": "The distance measure command can be used to measure the distance between all objects of two different object classes....",
			"type": "documentation"
		},
		{
			"title": "Measure intensity",
			"text": "underconstruction coming soon",
			"category": "Measurement",
			"url": "/docs/stable/commands/measurement/measure_intensity",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Median subtract",
			"text": "deprecated use rank filter link docs stable commands image_processing rank_filter md in combination with image math link docs stable commands image_processing image_math md instead for future projects median subtraction is a sort of noise filtering which can be used to reduce background noise similar to the rolling ball algorithm behind the scenes a rank filter is used to calculate the median of the image intensity which is subtracted afterwards from the original image the kernel size defines the window size used for the rank filter to calculate the median bigger kernels reduces more details from the image than smaller ones",
			"category": "Image Processing",
			"url": "/docs/stable/commands/image_processing/median_subtract",
			"blurb": "Deprecated Use [Rank filter]({% link docs/stable/commands/image_processing/rank_filter.md %}) in combination with...",
			"type": "documentation"
		},
		{
			"title": "Metrics",
			"text": "during an analysis imagec measures a couple of metrics of each detected object link docs stable fundamentals objects md all the measured data are stored in a sql database on disk internally we are using duckdb once the analysis is finished the collected data can be displayed within the imagec results viewer and either be exported to xlsx or r afterwards however as the number of data generated can be very large imagec allows to choose which data to display in the result view one way to specify the columns to show is using the class edit link docs stable first_steps operation md classification-tab dialog in the classification tab when the result file is opened after a run imagec displays the result columns as specified there even if a column is not specified the metric is still measured and can be added at any time even after the analysis has been completed metrics and statistics metrics-and-statistics a measurement in the context of imagec is a metrics calculated during the analysis for an object the statistics is applied to the selected measurement the following table gives an overview of the valid combinations of metics and statistics which are available plate view measurement statistics description ------------- --------------------- ----------------------- count cnt the average of the object number per image in the well intersection cnt the average of the number of objects a intersecting with object class b per image in the well area size avg the average of the average object area sizes per image in the well area size median the average of the median of the object area sizes per image in the well area size min the average of the minimum of the object area sizes per image in the well area size max the average of the maximum of the object area sizes per image in the well area size stdev the average of the standard deviations of the object area sizes per image in the well area size sum the average of the sum of the object area sizes per image in the well area size cnt the average number of objects per image in the well used to calculate the statistics perimeter avg the average of the average object perimeters per image in the well perimeter median the average of the median of the object perimeters per image in the well perimeter min the average of the minimum of the object perimeters per image in the well perimeter max the average of the maximum of the object perimeters per image in the well perimeter stdev the average of the standard deviations of the object perimeters per image in the well perimeter sum the average of the sum of the object perimeters per image in the well perimeter cnt the average number of objects per image in the well used to calculate the statistics circularity avg the average of the average object circularities per image in the well circularity median the average of the median of the object circularities per image in the well circularity min the average of the minimum of the object circularities per image in the well circularity max the average of the maximum of the object circularities per image in the well circularity stdev the average of the standard deviations of the object circularities per image in the well circularity sum the average of the sum of the object circularities per image in the well circularity cnt the average number of objects per image in the well used to calculate the statistics intensity min max avg avg the average of the average object intensities per image in the well intensity min max avg median the average of the median of the object intensities per image in the well intensity min max avg min the average of the minimum of the object intensities per image in the well intensity min max avg max the average of the maximum of the object intensities per image in the well intensity min max avg stdev the average of the standard deviations of the object intensities per image in the well intensity min max avg sum the average of the sum of the object intensities per image in the well intensity min max avg cnt the average number of objects per image in the well used to calculate the statistics well view measurement statistics description ------------- --------------------- ----------------------- count cnt the number of detected objects in the image intersection cnt the number of objects a intersecting with object class b in the image area size avg the average object area sizes in the image area size median the median of the object area sizes in the image area size min the minimum of the object area sizes in the image area size max the maximum of the object area sizes in the image area size stdev the standard deviations of the object area sizes in the image area size sum the sum of the object area sizes in the image area size cnt the number of objects in the image used to calculate the statistics perimeter avg the average object perimeters in the image perimeter median the median of the object perimeters in the image perimeter min the minimum of the object perimeters in the image perimeter max the maximum of the object perimeters in the image perimeter stdev the standard deviations of the object perimeters in the image perimeter sum the sum of the object perimeters in the image perimeter cnt the number of objects in the image used to calculate the statistics circularity avg the average object circularities in the image circularity median the median of the object circularities in the image circularity min the minimum of the object circularities in the image circularity max the maximum of the object circularities in the image circularity stdev the standard deviations of the object circularities in the image circularity sum the sum of the object circularities in the image circularity cnt the number of objects in the image used to calculate the statistics intensity min max avg avg the average object intensities in the image intensity min max avg median the median of the object intensities in the image intensity min max avg min the minimum of the object intensities in the image intensity min max avg max the maximum of the object intensities in the image intensity min max avg stdev the standard deviations of the object intensities in the image intensity min max avg sum the sum of the object intensities in the image intensity min max avg cnt the number of objects in the image used to calculate the statistics image view measurement statistics description ------------- --------------------- ----------------------- intersection - the number of objects intersecting with this object area size - the object area size perimeter - the object perimeters circularity - the object circularity intensity min - the object min intensity intensity max - the object max intensity intensity avg - the object avg intensity center of mass x - x coordinates of the center of mass of the object in the image center of mass y - y coordinates of the center of mass of the object in the image object id - unique object id origin object id - if it was copied by reclassify this is the object id of the object this object was copied from if not copied the value is 0 parent object id - if the object was reclassified using intersection this is the object id of the object this object was intersecting with if not reclassified the value is 0 tracking id - if the object has been tracked e g by coloc or timeframe all related objects will have the same tracking id the table is sorted by tracking id",
			"category": "Fundamentals",
			"url": "/docs/stable/fundamentals/metrics",
			"blurb": "During an analysis ImageC measures a couple of metrics of each detected [object]({% link...",
			"type": "documentation"
		},
		{
			"title": "Morphological transform",
			"text": "morphological transformation is an operation applied to the image shape usually binary images are used as input for this operation but can also applied to gray scale images imagec supports the basic operations erosion dilation opening and closing beside a couple of experimental operations a structuring element is applied to the input image performing the selected operation getting the output image the output image pixel values are calculated by an comparison of the corresponding input image pixels with its neighbors a structural element is a shape which is used to identify the pixel to be processed and the neighboring pixels used during the process the structuring element form is chosen according to the shape of the object which should be processed in the input image the centre of the structuring element is called the origin it identifies the pixel being processed the origin need not always be the centre but might be even outside of the structuring element imagec provides following options which allows to define the structual element and the algorithm settings the shape defines the form of the structural element to use theoretically any form can be used imagec actually supports circle square and cross as predefined elements to select the kernel size setting is used to define the size of the area looking for neighbor pixels with the iteration option the number of runs of the algorithm can be defined default is one run erosion erosion removes the boundaries of an object the core of the object remains as the result in a binary image a pixel is set to 1 if all of the neighboring pixels have the value 1 in a gray scale image the value of the output pixel is the minimum value of all pixels in the neighborhood erosion can be used to separate connected objects or remove noise from the image dilation underconstruction coming soon opening underconstruction coming soon closing underconstruction coming soon",
			"category": "Binary Image Processing",
			"url": "/docs/stable/commands/binary_image_processing/morphological_transform",
			"blurb": "Morphological transformation is an operation applied to the image shape. Usually, binary images are used as input for...",
			"type": "documentation"
		},
		{
			"title": "Noise filter",
			"text": "underconstruction coming soon",
			"category": "Filtering",
			"url": "/docs/stable/commands/filtering/noise_filter",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Object transform",
			"text": "underconstruction coming soon",
			"category": "Object Processing",
			"url": "/docs/stable/commands/object_processing/object_transform",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Objects",
			"text": "objects are the result of an image classification step link docs stable fundamentals classification md and represents the quantified data of an formally extracted region of interest objects are the final part of an imagec pipeline and are those elements which are finally stored to the results database each object is assigned to exact one object class to scope it together with the classification labels some object metrics are calculated imagec distinguishes between image plane link docs stable fundamentals image_formats md image-planes independent and image plane link docs stable fundamentals image_formats md image-planes dependent metrics image plane independent metrics are globally valid for the object whereby image plane dependent metrics are calculated based on the image pixel data tip see section metrics link docs stable fundamentals metrics md to get an overview of the image plane dependent object metrics confidence the confidence interpretation depends on the used segmentation mode for threshold segmentation the confidence value is the minimum threshold which was used to finally extract the object from the rest of the image the number range is from zero to 65535 if ai classifier is used the confidence value represents the output prediction probability of the used ai model the number range is from zero to one area size the area size is defined by the number of not black pixels within the shape of the extracted region of interest it s unit is px 2 perimeter the perimeter calculation has been ported from imagej to imagec the algorithm counts pixels in straight edges as 1 and pixels in corners as sqrt 2 it does this by calculating the total length of the roi boundary and subtracting 2- sqrt 2 for each non-adjacent corner for example a 1x1 pixel roi has a boundary length of 4 and 2 non-adjacent edges so the perimeter is 4-2 cdot 2- sqrt 2 a 2x2 pixel roi has a boundary length of 8 and 4 non-adjacent edges so the perimeter is 8-4 cdot 2- sqrt 2 circularity circularity defines the roundness of an object in other words how similar the object is to a circle the value is in range of zero to one whereby one stands for a perfect circle the circularity of an object is calculated as follows c frac 4 cdot pi cdot areasize perimeter 2 centroid the centroid is the geometrical center of an object this is the average of the x and y coordinates of all of the pixels in an object it s coordinates are calculated by the first order spatial moments c_x frac m_ 10 m_ 00 c_y frac m_ 01 m_ 00 bounding box the bounding box is the smallest square which can be drawn to include all pixels of the object within the box object id during the object detection of a run imagec assigns an id to each detected object starting with 1 for the first detected object this object id is unique throughout the entire run i e an object can be uniquely identified by this object id using the with object id option of the image save allows to plot the id beside the detected roi in the image together with the results table which also allows the id to be displayed each region of interest within the image can be matched to its metrics parent object id parent-object-id imagec allows to build up a hierarchy of objects during a run using the reclassify command once an object has been discovered and assigned to an object class the command can be used to change this class based on some criteria one of these criteria is the intersection of the object with an other one when this option is used imagec stores the object id of the intersecting object the parent as the parent object id together with the object with which the intersection is to be calculated an object can have exact zero or one parent origin object id once an object is duplicated using the reclassify copy option of the reclassify command the id of the origin object is stored together with the duplicated object the origin object id keeps the same even if a duplicated object is again duplicated tracking id the object id identifies an object uniquely within a run and the parent object id gives information about the hierarchy of the objects the tracking id on the other hand is used to link recognized objects that represent the same physical instance example for such same physical instances are colocalizing objects from different image channels or moving objects in two different time frames in the actual version of imagec the colocalizing tracking is supported by using the colocalization command when using the colocalizing command each object which colocalizes gets the same tracking id which allows later on to match those objects position nr of intersecting objects",
			"category": "Fundamentals",
			"url": "/docs/stable/fundamentals/objects",
			"blurb": "Objects are the result of an image [classification step]({% link docs/stable/fundamentals/classification.md %}) and...",
			"type": "documentation"
		},
		{
			"title": "Objects to binary",
			"text": "underconstruction coming soon",
			"category": "Object Processing",
			"url": "/docs/stable/commands/object_processing/objects_to_binary",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Operation",
			"text": "this guide takes you through your first steps with imagec helping you create your first imagec project and start analyzing images tip please read installation link docs installation index html first and run imagec on your computer before starting with this tutorial after download the correct imagec bundle for your computer unzip the downloaded data and use the imagec for linux and macos resp imagec exe for windows to start imagec the start page will be shown once imagec is successfully launched the tabs in the navigation pane on the left hand side are used to enter basic settings navigate from the left project tab over the image to the classification tab once all settings in these tabs are done you can start creating image processing pipelines in the pipeline tab project project-tab starting with the project settings basic information about the experiment and the used image setting must be done title description mandatory ------------- ----------------------- ---------- working directory storage directory of the images to be analyzed x experiment name title of the experiment stored together with the results scientist name of the person who is responsible for this analysis organization organization responsible for the analysis job name name of the job to identify the run auto generated if empty x group by images may be left ungrouped or can be grouped by filename regex or directory x filename regex if images are grouped by filename the regex should indicate the order of the images x regex test used to test the regex settings enter your image name and see if the wells are recognized in the regex test result z-stack define how to handle z-stacks in the images x t-stack define how to handle t-stacks in the images x well order if images are taken from in a 6 12 24 96 384 well format the order of the images position in the well can be determined here x plate size size of the uses microscopy plate x notes some free text notes on the experiment image grouping image-grouping-tab when grouping by foldername or filename is selected imagec will group the images based on these settings displays the images grouped by well in the results and calculates the statistics based on the determined group filename grouping uses regex regular expressions to extract the position on the plate and the position of the image in the well from the image filename extracted are plate row and column position and the image index in the well a change of the grouping settings after analysis is currently not supported by imagec if the grouping settings are changed the analysis has to be repeated warning make sure that the grouping options and regex settings are correct as they are needed for valid image sorting and mean well infos however if the grouping settings are wrong these statistics will also be calculated in a wrong way to extract the well position using regex from the filename correct it es expected that the row position in the filename is a character in the range of a-z and the column and index a decimal number a typical series of file names for the regex regexp _ 0-9 _ 0-9 might look something like the following name_a1_1 tif name_a1_2 tif name_a1_3 tif name_a1_4 tif name_a2_1 tif name_a2_2 tif name_a2_3 tif name_a2_4 tif to experiment with regular expressions have a look at regex101 working directory the working directory should be set to the folder where the images to be analyzed are stored imagec will perform a recursive folder search using the selected working directory as the base folder to find all supported image files all found files are listed in the images panel tip see section images for a full list of all supported image formats images images-tab once a working directory has been selected and the folder scan is complete all the images found will be listed in the table located in the images tab by clicking on an image the image meta information of the selected image is loaded and displayed in the properties table below the image selected in this tab is also the image used in the pipeline preview to the top a search field allows to filter the images in the list against its filename classification classification-tab first before creating pipelines and starting the analysis the object classes must be defined a separate object class must be defined for each different object type and population to be extracted from the images example object classes might be dapi nucleus cy7 spot cy5 spot coloc cy7cy5 imagec allows to either define your own classes load a preset of classes from a template or try to automatically populate classes using the magic stick button based on the image meta data and channels tip class names can consist of two parts separated by an the first part is used to sort the classes in the drop down boxes to help you keep track of them double click on a class opens the class editor the class editor is used to define the class name and the color used for all detected objects of this class in addition the metrics section allows to define the object metrics to be displayed per default in the results view however the measurement settings per object class can be changed at any time without having to rerun the analyses double click on a class opens the pipeline editor selected metrics are displayed per default in the results view after the analyses has been finished but can be changed at any time without having to rerun the analyses pipelines pipelines-tab the pipelines tab is used to create image processing pipelines which are used to extract objects of interest from the image channels imagec has no limit in the number of pipelines which can be added to a project during a analyzes imagec processes each active pipeline the optimal processing order and parallel processing of the different pipelines is determined by imagec automatically based on available cpu cores and possible pipeline dependencies by clicking on the arrow beside the plus button a drop down with predefined analyzing pipelines is opened all past evanalyzer pipelines are included in this version marked with the small ev icon to the left select ev channel for loading a pipeline preprocessing object filtering segmentation optimized for ev quantification from single vesicle imaging images with low background select cell brightfield for loading a pipeline preprocessing object filtering segmentation optimized for cell segmentation on brightfield images select nucleus for loading a pipeline preprocessing object filtering segmentation optimized for nucleus segmentation after fluorescent labelling of the nuclei e g hoechst dapi select ev in cell for loading a pipeline preprocessing object filtering segmentation optimized for ev quantification in complex material like cells just press the new pipeline button to start with an empty pipeline bestpractice it is a good practice to add one pipeline for each image channel to extract objects from and one pipeline for each object processing step like coloc or in cell counting by click on a pipeline the pipeline editor is opened on the left hand side the input and output options can be defined the input of a pipeline can either be an image channel or an empty image the pipeline steps box contains all commands which are applied on the input image all steps are performed from top to bottom each step can take either an image or a set of objects as input and either an image or a new set of objects as output based on the used command either the image is processed objects are extracted or objects are processed the color bar next to the command indicates the type of command tip see the section pipeline steps for detailed information about the available pipeline steps and their behavior gray commands manipulate images white command work on binary images and green commands work on objects translation commands translate the output from one input type to an other output type for example a threshold command translates an image grey into a binary image white and an object classification command translates a binary image white into objects green a live preview is displayed on the right it shows the resulting object segmentation after all applied pipelines steps changing a parameter will directly change the preview enabling a fast and easy adjustment and fine-tuning of the settings a live object count is displayed in the legend of the preview image based on image size and the complexity of the selected preprocessing algorithms it could take a couple of seconds for refreshing the preview the preview can additionally be zoomed in and out and a second window with the original image and the processed image side by side further enables smooth segmentation setting starting the analysis after all pipelines are created the analysis can be started by pressing the play button on the top a dialog box informs you about the progress of the analysis at the bottom left of the dialog a open results folder button is placed press this button to open the file explorer showing the folder with results of the actual analysis run with stop button a running analysis can be interrupted it may take a couple of minutes to stop a running analysis since all still in progress tasks have to be finished press the close button to close the dialog after a successful finished analysis run",
			"category": "First Steps",
			"url": "/docs/stable/first_steps/operation",
			"blurb": "This guide takes you through your first steps with ImageC, helping you create your first ImageC project and start...",
			"type": "documentation"
		},
		{
			"title": "Overview",
			"text": "first steps fundamentals",
			"category": "Stable",
			"url": "/docs/stable/index",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Overview",
			"text": "the goal in developing imagec was to use as few computing resources as possible this means that imagec can be executed on standard home computers and laptops as well as on high-performance computing clusters nevertheless even the most efficient image processing application requires at least a couple of hardware components to run smoothly this chapter gives an overview of the imagec footprint and hardware resources",
			"category": "Technical",
			"url": "/docs/stable/technical/overview",
			"blurb": "The goal in developing ImageC was to use as few computing resources as possible. This means that ImageC can be...",
			"type": "documentation"
		},
		{
			"title": "Overview",
			"text": "image processing image processing commands work on image planes manipulating the input image plane and forwarding the newly image to the command output imagec provides a set of image processing algorithm for different use cases in general image preprocessing serves to minimize the image noise as far as possible maximizing the signal-to-noise ratio in order to enable separation between the background and the signal an object segmentation command is issued after the image preprocessing tip image processing commands get an image as input and have a manipulated image as output object segmentation once objects are segmented the resulting region of interests have to be classified classification in imagec is the process of converting regions of interest into objects assigning each object to a class and calculating object metrics imagec provides an object classifier based on segmented images e g after applying a threshold and an ai classifier which can directly be applied to an image without the need of segmentation before tip see chapter classification for understanding the fundamentals",
			"category": "Commands",
			"url": "/docs/stable/commands/overview",
			"blurb": "Image processing Image processing commands work on image planes manipulating the input image plane and forwarding the...",
			"type": "documentation"
		},
		{
			"title": "Pipelines",
			"text": "clicking on an pipeline in the pipelines tab opens the pipeline settings panel the final goal of a pipeline in imagec is to get objects and classify them objects can either be extracted from an image plane based on a region of interest using image processing and classification algorithms or constructed from an existing set of objects using object math a typical way to extract objects from an image is to first define the image plane to be processed set the classification information for the extracted objects and add image preprocessing and classification steps then perform some object math and filtering finally the extracted objects are stored in the resulting database along with their object metrics pipeline settings the pipeline name input allows to give the pipeline a meaningful name it is recommended to not use the same name for two pipelines in the same project to make failure analyzes much more easier some of the processing steps are used to extract objects from the input images each detected object is classified by assigning to exact on class the object class setting allows to specify the default class that will be used for each detected object unless specified otherwise within a pipeline step pipeline input settings the pipeline input defines the image plane which should be used as a starting point for this pipeline mandatory field is the image channel if the z-stack setting in the project tab is set to intensity projection it is necessary to select which intensity projection mode is to be used for the input channel of the images by selecting the z-projection mode if the the z-stack setting in the project tab is set to each one nt additional settings have to be taken for the z-stack since each z-stack is processed individually if the z-stack setting in the project tab is set to exact one it is necessary to specify which z-stack index to use for analysis the default being zero 0 same settings have to be taken for the time stack depending on taken t-stack settings in the project tab in addition to start with an image plane as input it is also possible to start with an empty image using a blank image is useful for use cases where you are working with objects from a previous pipeline without having to extract objects again pipeline steps commands are used to manipulate the input image extract objects or to work on exiting objects a command takes either an image plane or objects as input and returns a manipulated image or objects as output in other words based on the command category the command either works on images or objects or transforms an image into an object or vice versa this brings us to four principal categories of commands image processing commands gray object segmentation commands white object classification commands and object post-processing commands green as not every sequence of commands is possible in a meaningful way imagec indicates which command can be connected to the previous one the goal of each pipeline is to extract regions of interest from an image input plane and store these regions of interest as objects for further object processing imagec provides a wide range of commands that can be used for this purpose by clicking on the --- --- button within the pipeline step section the command selection dialog is opened commands are classified into four principal categories image processing commands gray object segmentation commands white object classification commands and object post-processing commands green when opening the command selection dialogue this dialogue shows all the available commands that can be used at this pipeline position double-click to insert the command a typical pipeline flow might look like this first of all image processing commands are used to reduce the image noise as much as possible object segmentation commands are used to separate foreground from background by using threshold algorithms and convert the grey scale image to a binary image in the next step an object classification command is used to extract region of interests from the grey scale image and classify them to objects object postprocessing and filter commands can be used to do further processing or filtering on the detected objects pipeline history using the history button to open the pipeline history the history list shows the last 64 changes taken in this pipeline the history tab allows you to go back in time and restore a setting by double-clicking on an entry in the history the tag button can be used to mark the actual settings within the history which allows an easy restore of these settings",
			"category": "Fundamentals",
			"url": "/docs/stable/fundamentals/pipelines",
			"blurb": "Clicking on an pipeline in the Pipelines tab opens the pipeline settings panel. The final goal of a pipeline in...",
			"type": "documentation"
		},
		{
			"title": "Rank filter",
			"text": "with ranking filters the grey values of the pixels in a defined area around a pixel are collected sorted by size and ranked a grey value is then selected from this sorted list to replace the grey value of the current pixel the radius setting defines the size of the area to collect the pixels gray values in tip bigger filter kernels removes more noise and details from the image rank-order filters belong to the class of non-linear filters in digital image processing these are filters that cannot be described by a convolution with ranking filters the gray values of the pixels in a defined area around a pixel are collected sorted by size and ranked a gray value is then selected from this sorted list to replace the gray value of the current pixel the choice of position determines the type of ranking filter with ascending sorting you get the minimum filter for the minimum gray value first position in the list median filter for the gray value in the middle of the list maximum filter for the maximum gray value last position in the list",
			"category": "Image Processing",
			"url": "/docs/stable/commands/image_processing/rank_filter",
			"blurb": "With ranking filters, the grey values of the pixels in a defined area around a pixel are collected, sorted by size...",
			"type": "documentation"
		},
		{
			"title": "Reclassify",
			"text": "the reclassify command can be used to change the class of an object that has been formally classified using the classifier link docs stable commands classification classifier md or ai-classifier link docs stable commands classification classifier_ai md command based on some filter criteria this allows to create further fine granular object populations typical use case for instance are the separation of spots in cell and outside a cell which can be managed using the intersection filter or the separation of bright and less bright spots for that reason the imagec reclassifier provides two filter options intersection and intensity an object hierarchy is built up by storing a parent object id together with each object this information can be used to draw a hierarchy graph of the objects showing which objects are part of another use the intersection filter of the reclassify command to build up such a hierarchy filters intersection filter the intersection filter takes an intersection object class as input and is applied to those objects of the input input class that intersect with any of these objects imagec can create a object hierarchy see section parent object id link docs stable fundamentals objects md parent-object-id when using the intersection filter the object hierarchy allows to answer the questions which objects are contained within another object and how many objects intersect another object the parent information is stored in the intersecting object from the input object input class whereby the parent object is the intersecting object from the intersecting object input class imagec allows you to specify whether or not to create a hierarchy for intersecting objects by specifying the hierarchy mode create hierarchy this option stores the parent information for intersecting objects existing hierarchy information is retained which allows to build up a full hierarchy tree e g parent of nucleus is cell parent of spot is nucleus which allows to answer the questions give me the spots within a cell and give me the spots within a cell in the nucleus of this cell keep existing this option does not change the hierarchy information of the intersecting object remove hierarchy information this option removes the parent object id from the intersecting objects intensity filter this filter allows to specify a min and max intensity measured in the defined image channel if the measured object intensity is within this intensity range the filter is applied intensity filter and intersection filter can both be activated only if both filters match the filter for the object is applied match handling once the filter matches one of the move or copy operations will be applied to the objects that match the filter the move operator applies a new object class to the object object id keeps the same as before the copy operator creates a new object and assigns the new object class only to the new object a new object id is generated and the origin object id of the newly created object is set to the object id of the origin object the origin object keeps untouched",
			"category": "Object Processing",
			"url": "/docs/stable/commands/object_processing/reclassify",
			"blurb": "The reclassify command can be used to change the class of an object that has been formally classified using the...",
			"type": "documentation"
		},
		{
			"title": "Resources and Limits",
			"text": "minimum hardware requirements more is always better component minimum ----------- ---------- cpu 64 bit 1 ghz dual core preferred 2 ghz ram 2 gb of free ram 0 5 gb for each additional cpu core storage 500 mb free storage for installation screen minimum recommended resolution 1528x980 graphic card optional nvidia graphical card with cuda support limits see section image formats link docs stable fundamentals image_formats md for a list of supported image formats limit default value --- --- max classes 32 max image series 10 max image channels 10 max z-stack images 65535 max t-stack images 2 billion max number of objects 1 billion max number of pipelines 65535 maximum tile size 46340x46340",
			"category": "Technical",
			"url": "/docs/stable/technical/limits",
			"blurb": "Minimum hardware requirements. More is always better ;) ... Component | Minimum ----------- |---------- CPU |64 bit,...",
			"type": "documentation"
		},
		{
			"title": "Results",
			"text": "imagec stores the results of a analysis run within a database file named results icdb results from a previous run can be opened by clicking the arrow beside the open button on the toolbar once a results file is opened the first time the measurement values selected in the class editor link docs stable first_steps operation md classification-tab are displayed in the table plate view to add additional metrics press the blue add column button the opened add column dialog displays all available metrics which can be added to the table imagec saves the actual table settings with the database file so that they are restored the next time the results are opened see section metrics link docs stable fundamentals metrics md for a complete description of the available metrics plate view imagec opens the plate view panel per default the plate shows the results grouped by well as average value of the selected statistics from the images of the group image grouping must be setup before the analyze is started in the project tab if ungrouped was selected as group by method the plate view is not shown and imagec directly jumps to the image list view using the heatmap button the view can be switched from a table view to a heatmap view wells are coloured using a heatmap calculated from all data displayed with the mean value of all wells as the centre of the spectrum and the minimum and maximum as the outer left and outer right limits of the spectrum in heatmap view a dropdown in the toolbar allows to select which column of the table should be displayed as heatmap image view a double click on a well in the heatmap view or a column in the table view will prompt the opening of a detailed view of the selected well the image view displays each image of the well ordered by the image index specified in the well order matrix the image index was extracted from the filename during the analysis using the specified regex to reorder the image position displayed in the well view matrix use the well order settings field a string formatted order matrix can be used to customize the order of images displayed in the well order matrix per default the matrix is set to 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 the numbers in the square brackets are the image indexes where each comma-separated square block represents a row and the comma-separated numbers represent columns this results in the following screen sequence for the example above if images are to be excluded from the statistics this can be done via the exclude menu item icon_unavailable as invalid marked images are crossed out and are not taken into account in all subsequent calculations image detail view image-detail-view to go one step deeper looking into detail information about a single image double click on an image in the image view the density view presents a density map of the image in the bottom left sidebar the are size to b used for calculate the density map can be chosen imagec calculates the average value of the selected measurement of all valid objects within this squares the square size can be changed using the left hand side panel be careful though if the square size is too small for large images you may run out of ram tip it is possible to view the details for multiple images at once by selecting the image rows in the table view and using the open arrow in the navigation bar interactive mode interactive-mode in image detail view mode imagec displays the metrics for each individual detected object when an object in the table is selected imagec opens the image that the object was extracted from and highlights the position in the image where the object was found the position of each object in the image can be identified using this feature however imagec needs access to the original images for a correct working interactive mode if the results icdb file or the images are moved imagec will prompt you to specify the new storage location bestpractice for imagec to automatically find the images for interactive mode it is best practice to keep the results icdb file in its original folder as this was where it was generated - - - - imagec - - results icdb data export data-export the download button icon_download allows the current settings to be exported as either xlsx or r",
			"category": "First Steps",
			"url": "/docs/stable/first_steps/results",
			"blurb": "ImageC stores the results of a analysis run within a database file named results.icdb . Results from a previous run...",
			"type": "documentation"
		},
		{
			"title": "Rolling ball",
			"text": "the rolling ball algorithm is a background subtraction algorithm with the goal to remove most of the background noise this is achieved by creating a local background around a virtual ball within the radius of the ball the average intensity is calculated this is done for the entire image the result is subtracted from the original image this port from imagej contains two ball types a spheral ball and a paraboloid a paraboloid handles edges more gently reducing the appearance of artifacts along boundaries this is beneficial in applications such as microscopy where accurate boundary representation is essential bestpractice the radius of the ball should be set to at least the size of the largest object that does not belong to the background note the implementation in imagec was taken from the original imagej and ported to c based on the nih image pascal version by michael castle and janice keller of the university of michigan mental health research institute the rolling-ball algorithm was inspired by stanley sternberg s article biomedical image processing ieee computer january 1983",
			"category": "Image Processing",
			"url": "/docs/stable/commands/image_processing/rolling_ball",
			"blurb": "The rolling ball algorithm is a background subtraction algorithm, with the goal to remove most of the background...",
			"type": "documentation"
		},
		{
			"title": "Save control image",
			"text": "underconstruction coming soon",
			"category": "Object Processing",
			"url": "/docs/stable/commands/object_processing/save_control_image",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Spot count",
			"text": "underconstruction coming soon",
			"category": "Evanalyzer",
			"url": "/docs/stable/tutorials/evanalyzer/spot_count",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Spot count",
			"text": "underconstruction coming soon",
			"category": "Evanalyzer",
			"url": "/docs/stable/tutorials/evanalyzer/spot_count_per_cell",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Spot count",
			"text": "underconstruction coming soon",
			"category": "Evanalyzer",
			"url": "/docs/stable/tutorials/evanalyzer/spot_coloc",
			"blurb": "",
			"type": "documentation"
		},
		{
			"title": "Testing",
			"text": "still under construction imagec executes testing pipeline before a new releases is published these testing pipelines are placed in the https github com joda01 imagec-test repository",
			"category": "Dev",
			"url": "/docs/stable/dev/testing",
			"blurb": "Still under construction ImageC executes testing pipeline before a new releases is published. These testing pipelines...",
			"type": "documentation"
		},
		{
			"title": "Threshold",
			"text": "threshold is an object segmentation method with the goal to separate foreground objects from background objects applying a threshold to an image converts the grey scale image to a binary image all pixels with an intensity value below the selected threshold value are converted to zero black the others are to 65535 white using the correct threshold will have a significant effect on the quality of the result the challenge is to find a threshold value that is high enough to suppress the background noise but not too high as to not remove objects of interest looking on the histogram of an image can help to find a good starting point when using manual threshold value set the minimum threshold value to the smallest intensity value of the signal most left value after the signal in the histogram tip using the icon_external_link button to open the advanced preview the histogram of the image is displayed in the left image pane bestpractice set the minimum threshold value to the smallest intensity value of the signal most left value after the signal in the histogram as a good starting point thresholding is a technique that aims to achieve an intensity value that is higher than the highest intensity value of the background noise and low enough to achieve the lowest intensity value of the regions of interest rois image preprocessing helps in advanced to reduce the background noise to get a sharp intensity border between background and foreground see also section threshold filter link docs stable commands filtering threshold_filter md maximum threshold using a minimum thresholds sets the minimum signal intensity to segment an object however there may be use cases having different objects in an image with different signal intensity values using a max threshold allows to limit the maximum signal intensity for segmenting an object too together with the minimum threshold the maximum threshold can be used either for more detailed object differentiation or for example to extract the background instead of the objects when the minimum threshold is set to zero tip a object is only segmented if the signal value is between minimum threshold value and maximum threshold value threshold classes threshold-classes in addition to only separating background and foreground using a minimum and maximum threshold imagec also allows more than one threshold to be applied to an image use the icon_add button in the threshold dialogue box to define additional thresholds for the image a threshold class must be selected for each defined threshold in order to distinguish between objects segmented with different threshold values under the hood imagec assigns each threshold class to a well-defined pixel value in the binary image starting from 65535 full white down to one based on this value the later on classifier is able to distinguish the segmented objects tip multiple thresholds are assigned to threshold classes allowing different objects to be detected depending on their signal strength auto threshold using a manual threshold applies the same threshold for all images of your set if the exposure ratios of the images are very different it is possible that no uniform threshold value can be found for all images you can choose one of imagec s provided auto-threshold algorithms for this the selected algorithm attempts to identify a minimum threshold value through the analysis of statistical properties inherent to the image in question the precise methodology employed is contingent upon the specific algorithm utilized minimum threshold in combination with auto threshold auto thresholds can be effective if the preprocessing steps are sufficiently robust in removing background noise however it is a common practice in research to include control images devoid of any objects as samples since the auto threshold algorithms are designed to find an upper bound that separates background from signal these algorithms will also find such a bound in an empty image due to noise applying an auto threshold algorithm to an empty noise image will lead to the segmentation of noise it is therefore strongly advised that a minimum threshold value exceeding zero is set even when an auto threshold method is employed imagec will use the chosen minimum threshold as a lower bound if the auto threshold algorithm calculates a threshold value below the lower bound imagec will set it to the minimum value it is advisable to select an empty control image an image without an object from the list by using the live preview and the histogram it is possible to determine the intensity value of the background noise and set a suitable minimum value for the threshold bestpractice in the event that an auto threshold algorithm is employed it is strongly recommended to establish a minimum threshold this is to prevent the occurrence of false positive detection in images that lack objects given that such images would otherwise be included in the analysis",
			"category": "Binary Image Processing",
			"url": "/docs/stable/commands/binary_image_processing/threshold",
			"blurb": "Threshold is an object segmentation method with the goal to separate foreground objects from background objects....",
			"type": "documentation"
		},
		{
			"title": "Threshold filter",
			"text": "to get comparable results in one experiment it is common to use the same manual threshold value for all images nevertheless given the considerable range of exposure times for images it is possible that the selected threshold value may prove insufficient for some images this leads to a kind of overexposed image after the threshold in which the background is erroneously recognized as a signal to filter out images that are affected by this problem imagec offers a threshold filter filter in the event that the selected threshold value is less than the value observed at the maximum of the image histogram multiplied by the aforementioned factor the filter is applied the intensity value at the maximum of the histogram of the image multiplied by the threshold filter defines the area of allowed threshold values for the image if the min threshold value is lower than the lowe bound of this area the image id filtered out",
			"category": "Filtering",
			"url": "/docs/stable/commands/filtering/threshold_filter",
			"blurb": "To get comparable results in one experiment, it is common to use the same manual threshold value for all images....",
			"type": "documentation"
		},
		{
			"title": "Tutorials",
			"text": "the tutorial section contains compact examples that are centered a single goal which should help to learn working with imagec s pipelines",
			"category": "Tutorials",
			"url": "/docs/stable/tutorials/overview",
			"blurb": "The tutorial section contains compact examples that are centered a single goal which should help to learn working...",
			"type": "documentation"
		},
		{
			"title": "Voronoi",
			"text": "in order to construct a voronoi diagram it is necessary to gather certain fundamental data this information can be obtained from the voronoi settings tab which is used for the voronoi diagram construction process a voronoi diagram also known as a thiessen polygon or dirichlet decomposition represents a decomposition of space into regions that are determined by a given set of points in space referred to here as centres the diagram areas are generated so that the enveloping area of each point is the closest to that point voronoi diagrams can be useful for approximating cell surfaces based on known cell nuclei voronoi centers a voronoi diagram is constructed using points in space as the fundamental building blocks the voronoi centers defines the object classes which imagec should use the take the points in space from the centre of mass is used as the initial point for the voronoi construction process from the valid regions of interest identified within the selected channel bestpractice typical voronoi centers are nuclei max radius with setting max radius the area of a voronoi diagram can be limited by its radius this option is particularly beneficial in scenarios where cells must be approximated based on provided nuclei yet the cell density is exceedingly low remove the value if no are size limitation should be done masking class imagec offers the option to overlay and intersect a calculated voronoi diagram with another surface this option is particularly beneficial in scenarios where a cell area channel exists the intersection of the calculated voronoi grid with the cell area channel results in a more accurate cell approximation as any areas that are not part of the actual terrain are removed object filter object filter in voronoi slots are applied to the calculated voronoi diagram areas beside the option to exclude voronoi diagram areas based on its size two more advanced options exclude areas at the edges and exclude areas without center are available exclude areas at the edges when this filter is active all areas that touch the edge of the image are marked as invalid exclude areas without center the voronoi diagram is computed based on a set of points which are the centres of the computed voronoi diagram areas when using the voronoi diagram in combination with a masking class it can happen that after applying the mask areas are left that don t have a centre point anymore enabling this filter will invalidate all areas that do not contain a point from the source point set bestpractice it is recommended to enable this option if nuclei are used as a set of points and cell areas as a clipping mask applying this filter option will filter out all left areas that do not contain nuclei",
			"category": "Object Processing",
			"url": "/docs/stable/commands/object_processing/voronoi",
			"blurb": "In order to construct a Voronoi diagram, it is necessary to gather certain fundamental data. This information can be...",
			"type": "documentation"
		},
		{
			"title": "Watershed",
			"text": "the watershed algorithm employs a process of object segmentation separation based on the intensity values of the objects in question in this context the intensity values are interpreted as altitude with the objective of identifying the valleys between the peaks in applications with a high object density it is no exception that two objects come very close or even touch each other when using threshold techniques for object segmentation it is not possible to distinguish between two such near objects anymore some algorithms have been developed with the specific aim of addressing this issue one of them is the watershed algorithm which was ported from imagej to imagec for that reason tip use the tolerance value to define on which percentage of the extracted intensity level an object border os detected warning it is recommended that the watershed be activated only when necessary as it is a highly complex algorithm that significantly reduces analysis time when activated based on peaks extracted from the intensity values the valleys between the peaks are the borders for splitting objects",
			"category": "Binary Image Processing",
			"url": "/docs/stable/commands/binary_image_processing/watershed",
			"blurb": "The watershed algorithm employs a process of object segmentation/separation based on the intensity values of the...",
			"type": "documentation"
		},
		{
			"title": "Yest cell detection",
			"text": "imagec is shipped with a predefined pipelines for yest cell detection in brightfield images in this tutorial we will go step by step through this pipeline template before you start creating the pipeline look at your image and identify the metrics that distinguish your objects of interest from the rest of the image when we examine the yeast cells in bright field a very strong characteristic is the cell membrane which is shown as a bold dark border so let s find a pipeline which finds this border intensity first we use the intensity command to adapt the brightness of the image based on the image exposure blur to find the border we will use an edge detection algorithm however such algorithms react on intensity changes in the image noise per definition generates a lot of small such sharp intensity changes in an image therefore we use a gaussian blur as our second step in the pipeline the gaussian blur protects real edges in the image from being blured away but removed noise efficiently canny edge detection the canny edge detection algorithm is now applied converting the grayscale image into a binary image containing only the detected edges blur the edges again to fill the are inside the circle with more contrast threshold the background is removed when we reach the final threshold which results in the cell body becoming more visible hough transformation is used to find circles which represents our cells in the image voronoi the voronoi algorithm is used to separate the cells from each other",
			"category": "Advanced",
			"url": "/docs/stable/tutorials/advanced/yest_cell_detection",
			"blurb": "ImageC is shipped with a predefined pipelines for Yest cell detection in brightfield images. In this tutorial we will...",
			"type": "documentation"
		}
	]
}